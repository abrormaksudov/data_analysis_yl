{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b94d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f49d256f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1009, 19)\n",
      "['user_id', 'region', 'device', 'channel', 'session_start', 'session_end', 'sessiondurationsec', 'session_date', 'month', 'day', 'hour_of_day', 'order_dt', 'revenue', 'payment_type', 'promo_code', 'final_price', 'time_of_day', 'payer', 'week']\n"
     ]
    }
   ],
   "source": [
    "dates = ['session_start', 'session_end', 'session_date', 'order_dt']\n",
    "df = pd.read_csv('ecom_go_2.csv', parse_dates=dates)\n",
    "df['week'] = pd.to_datetime(df['session_date']).dt.isocalendar().week\n",
    "df_pl = pl.from_pandas(df)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5d520dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1009, 19) 282\n",
      "(1009, 19) 282\n",
      "(1003, 19) 276\n"
     ]
    }
   ],
   "source": [
    "df_unchanged = df.copy()\n",
    "print(df_unchanged.shape, df_unchanged['payer'].sum())\n",
    "\n",
    "df_replaced = df.copy()\n",
    "df_replaced['revenue'] = np.where(df_replaced['revenue'] == 100000, 9999, df_replaced['revenue'])\n",
    "df_replaced['revenue'] = np.where(df_replaced['revenue'] == 1, 4999, df_replaced['revenue'])\n",
    "print(df_replaced.shape, df_replaced['payer'].sum())\n",
    "\n",
    "df_removed = df.copy()\n",
    "to_remove = df[df['revenue'].isin([1, 100000])].index\n",
    "df_removed.drop(to_remove, inplace=True)\n",
    "print(df_removed.shape, df_removed['payer'].sum())\n",
    "\n",
    "\n",
    "dfs = [(df_unchanged, \"ORIGINAL DATAFRAME:\"), \n",
    "       (df_replaced, \"REPLACED DATAFRAME:\"), \n",
    "       (df_removed, \"REMOVED DATAFRAME:\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f673dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223f4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replaced.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd425f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hour_of_day.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7527b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.time_of_day.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef8f2e2",
   "metadata": {},
   "source": [
    "# Predict Daily Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b113fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_order = [\n",
    "    'organic', \n",
    "    'email-рассылки', \n",
    "    'реклама у блогеров', \n",
    "    'социальные сети', \n",
    "    'контекстная реклама'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c7384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "columns_to_keep = [\n",
    "    'region', 'device', 'channel', 'payment_type',\n",
    "    'is_weekend', 'day', 'month', \n",
    "    'hour_of_day', 'sessiondurationsec', 'time_to_purchase',\n",
    "    'promo_code', 'payer' \n",
    "]\n",
    "\n",
    "df['time_to_purchase'] = (df['order_dt'] - df['session_start']).dt.total_seconds().fillna(-1)\n",
    "df['is_weekend'] = df['day'].isin([6, 7]).astype(int)\n",
    "df['promo_code'] = df['promo_code'].fillna(0)\n",
    "df['payment_type'] = df['payment_type'].fillna('No Purchase')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('channel', OrdinalEncoder(categories=[channel_order]), ['channel']),\n",
    "        \n",
    "        ('nominal_cat', OneHotEncoder(handle_unknown='ignore'), [\n",
    "            'region', 'device', 'payment_type'\n",
    "        ]),\n",
    "        \n",
    "        ('numeric', StandardScaler(), [\n",
    "            'is_weekend', 'day', 'month', \n",
    "            'hour_of_day', 'sessiondurationsec', \n",
    "            'time_to_purchase', 'promo_code', 'payer'\n",
    "        ])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X = df[columns_to_keep]\n",
    "y = df['revenue']\n",
    "\n",
    "# Transform features\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "print(X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c9c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared Score:\", r2)\n",
    "\n",
    "# Determine the correct number of coefficients based on the preprocessor\n",
    "def get_feature_names(column_transformer):\n",
    "    feature_names = []\n",
    "    \n",
    "    # Channel (Ordinal Encoder)\n",
    "    feature_names.extend([f'channel_{c}' for c in channel_order])\n",
    "    \n",
    "    # OneHotEncoder categories\n",
    "    onehot = column_transformer.named_transformers_['nominal_cat']\n",
    "    for i, cat_list in enumerate(onehot.categories_):\n",
    "        feature_names.extend([f'{onehot.feature_names_in_[i]}_{c}' for c in cat_list])\n",
    "    \n",
    "    # Numeric features\n",
    "    numeric_features = ['is_weekend', 'day', 'month', 'hour_of_day', 'sessiondurationsec', 'time_to_purchase', 'promo_code', 'payer']\n",
    "    feature_names.extend(numeric_features)\n",
    "    \n",
    "    return feature_names\n",
    "\n",
    "# Get feature names\n",
    "feature_names = get_feature_names(preprocessor)\n",
    "\n",
    "# Create DataFrame of coefficients\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure coefficient length matches feature names\n",
    "coefficients = pd.DataFrame({\n",
    "    'feature': feature_names[:len(model.coef_)],\n",
    "    'coefficient': model.coef_\n",
    "})\n",
    "coefficients = coefficients.sort_values('coefficient', key=abs, ascending=False)\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(coefficients.head(10))\n",
    "\n",
    "# Additional model diagnostics\n",
    "print(\"\\nIntercept:\", model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0723529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names\n",
    "\n",
    "# Combine encoded feature names\n",
    "encoded_feature_names = (\n",
    "    channel_encoded_names + \n",
    "    [f'region_{r}' for r in region_encoded_names] + \n",
    "    [f'device_{d}' for d in device_encoded_names] + \n",
    "    [f'payment_type_{p}' for p in payment_type_encoded_names]\n",
    ")\n",
    "\n",
    "# Add remaining column names\n",
    "remaining_feature_names = [\n",
    "    'is_weekend', 'day', 'month', \n",
    "    'hour_of_day', 'sessiondurationsec', 'time_to_purchase',\n",
    "    'promo_code', 'payer'\n",
    "]\n",
    "\n",
    "# Combine all feature names\n",
    "all_feature_names = encoded_feature_names + remaining_feature_names\n",
    "\n",
    "# Convert to DataFrame\n",
    "X_transformed_df = pd.DataFrame(\n",
    "    X_transformed, \n",
    "    columns=all_feature_names,\n",
    "    index=X.index\n",
    ")\n",
    "X_transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3951e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['order_dt'] - df['session_start']).dt.total_seconds().fillna(-1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f96a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['time_to_purchase'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a26f18",
   "metadata": {},
   "source": [
    "### `Encoding Categories`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8418dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def prepare_dataframe(df):\n",
    "    columns_to_keep = [\n",
    "        'user_id', 'region', 'device', 'channel', \n",
    "        'session_date', 'sessiondurationsec', 'hour_of_day', \n",
    "        'day', 'month', 'revenue', \n",
    "        'payment_type', 'promo_code', 'payer'\n",
    "    ]\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "def create_feature_encoder():\n",
    "    channel_order = [\n",
    "        'organic', \n",
    "        'email-рассылки', \n",
    "        'реклама у блогеров', \n",
    "        'социальные сети', \n",
    "        'контекстная реклама'\n",
    "    ]\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('channel_encoder', \n",
    "             OrdinalEncoder(categories=[channel_order]), \n",
    "             ['channel']),\n",
    "            \n",
    "            ('region_encoder', \n",
    "             OneHotEncoder(drop='first', sparse_output=False), \n",
    "             ['region']),\n",
    "            \n",
    "            ('device_encoder', \n",
    "             OneHotEncoder(drop='first', sparse_output=False), \n",
    "             ['device']),\n",
    "            \n",
    "            ('payment_type_encoder', \n",
    "             OneHotEncoder(drop='first', sparse_output=False), \n",
    "             ['payment_type'])\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "df_prepared = prepare_dataframe(df_replaced)\n",
    "preprocessor = create_feature_encoder()\n",
    "X_encoded = preprocessor.fit_transform(df_prepared)\n",
    "\n",
    "feature_names = (\n",
    "    ['channel_encoded'] + \n",
    "    [f'region_{r}' for r in preprocessor.named_transformers_['region_encoder'].categories_[0][1:]] +\n",
    "    [f'device_{d}' for d in preprocessor.named_transformers_['device_encoder'].categories_[0][1:]] +\n",
    "    [f'payment_type_{p}' for p in preprocessor.named_transformers_['payment_type_encoder'].categories_[0][1:]] +\n",
    "    list(df_prepared.columns[~df_prepared.columns.isin(['region', 'device', 'channel', 'payment_type'])])\n",
    ")\n",
    "\n",
    "df_encoded = pd.DataFrame(X_encoded, columns=feature_names, index=df_prepared.index)\n",
    "\n",
    "def engineer_features(df_encoded):\n",
    "    # Weekday vs Weekend\n",
    "    df_encoded['is_weekend'] = df_encoded['day'].isin([6, 7]).astype(int)\n",
    "    \n",
    "    # Peak hours (9-17)\n",
    "    df_encoded['is_peak_hour'] = ((df_encoded['hour_of_day'] >= 9) & \n",
    "                                   (df_encoded['hour_of_day'] < 17)).astype(int)\n",
    "    \n",
    "    # Session duration buckets\n",
    "    duration_percentiles = df_encoded['sessiondurationsec'].quantile([0.33, 0.67])\n",
    "    df_encoded['session_duration_category'] = pd.cut(\n",
    "        df_encoded['sessiondurationsec'], \n",
    "        bins=[-float('inf'), duration_percentiles[0.33], \n",
    "               duration_percentiles[0.67], float('inf')],\n",
    "        labels=[0, 1, 2]\n",
    "    )\n",
    "    \n",
    "    # Interaction features\n",
    "    region = [f'region_{r}' for r in preprocessor.named_transformers_['region_encoder'].categories_[0][1:]]\n",
    "    for cat in ['channel_encoded'] + region:  # adjust these to match your encoded column names\n",
    "        for other in ['hour_of_day', 'day']:\n",
    "            df_encoded[f'{cat}_{other}_interaction'] = df_encoded[cat] * df_encoded[other]\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "df_encoded = engineer_features(df_encoded)\n",
    "# df_encoded['hour_of_day'] = df_encoded['hour_of_day'].astype(int)\n",
    "# # Average session duration per channel\n",
    "# channel_avg_duration = df_encoded.groupby('channel_encoded')['sessiondurationsec'].transform('mean')\n",
    "# df_encoded['channel_avg_session_duration'] = channel_avg_duration\n",
    "# # Convert hour to sine/cosine to capture cyclical nature\n",
    "# df_encoded['hour_sin'] = np.sin(df_encoded['hour_of_day'] * (2 * np.pi / 24))\n",
    "# df_encoded['hour_cos'] = np.cos(df_encoded['hour_of_day'] * (2 * np.pi / 24))\n",
    "# # Frequency of payers per channel\n",
    "# channel_payer_freq = df_encoded.groupby('channel_encoded')['payer'].transform('mean')\n",
    "# df_encoded['channel_payer_frequency'] = channel_payer_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e752496",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 40))\n",
    "sns.heatmap(df_encoded.corr(), annot=True, cmap='coolwarm', fmt='.2f', annot_kws={\"fontsize\": 20})\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.tick_params(axis='x', labelsize=20)\n",
    "plt.tick_params(axis='y', labelsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96c7a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate daily revenue\n",
    "daily_revenue = df_encoded.groupby('session_date')['revenue'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "921915fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_daily_features(df_encoded):\n",
    "    # Daily aggregations\n",
    "    daily_features = df_encoded.groupby('session_date').agg({\n",
    "        'sessiondurationsec': ['mean', 'sum'],\n",
    "        'channel_encoded': 'mean',\n",
    "        'hour_of_day': 'mean',\n",
    "        'day': 'mean',\n",
    "        'payer': 'sum'  # Number of paying users\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Flatten column names\n",
    "    daily_features.columns = ['session_date', 'avg_session_duration', 'total_session_duration', \n",
    "                               'avg_channel', 'avg_hour', 'avg_day', 'paying_users']\n",
    "    \n",
    "    # Lagged features (previous day's revenue)\n",
    "    daily_features['prev_day_revenue'] = daily_revenue['revenue'].shift(1)\n",
    "    \n",
    "    # Day of week feature\n",
    "    daily_features['day_of_week'] = pd.to_datetime(daily_features['session_date']).dt.dayofweek\n",
    "    \n",
    "    return daily_features.dropna()  # Remove first row due to lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fd50fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "daily_features = create_daily_features(df_encoded)\n",
    "daily_features = daily_features.merge(daily_revenue, on='session_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9846b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Prepare features and target\n",
    "X = daily_features.drop(['session_date', 'revenue'], axis=1)\n",
    "y = daily_features['revenue']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c5ca80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Results:\n",
      "Mean Absolute Error: 1269.6609772249953\n",
      "Mean Squared Error: 6669599.663132971\n",
      "R-squared Score: 0.9358713849707991\n",
      "\n",
      "Ridge Regression Results:\n",
      "Mean Absolute Error: 1286.227750436165\n",
      "Mean Squared Error: 6889170.429294408\n",
      "R-squared Score: 0.9337601984159798\n",
      "\n",
      "Random Forest Results:\n",
      "Mean Absolute Error: 1222.4108108108107\n",
      "Mean Squared Error: 6208740.8253999995\n",
      "R-squared Score: 0.9403025713208806\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"Mean Absolute Error:\", mae)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    print(\"R-squared Score:\", r2)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Try different models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_r2 = -float('inf')\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name} Results:\")\n",
    "    trained_model = evaluate_model(model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    \n",
    "    # Track best model\n",
    "    r2 = r2_score(y_test, trained_model.predict(X_test_scaled))\n",
    "    if r2 > best_r2:\n",
    "        best_model = trained_model\n",
    "        best_r2 = r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37347c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure the columns are datetime objects\n",
    "df['order_dt'] = pd.to_datetime(df['order_dt'])\n",
    "df['session_start'] = pd.to_datetime(df['session_start'])\n",
    "\n",
    "# Calculate the time difference in seconds\n",
    "time_diff_seconds = (df['order_dt'] - df['session_start']).dt.total_seconds()\n",
    "print(time_diff_seconds.unique().tolist())\n",
    "# Create a histogram plot\n",
    "# sns.histplot(time_diff_seconds)  # kde=True adds a kernel density estimate for smoothness\n",
    "# plt.title(\"Time Difference in Seconds between Order and Session Start\")\n",
    "# plt.xlabel(\"Time Difference (seconds)\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5871c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "7 * 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['sessiondurationsec'] / 3660).unique().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deca736",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['session_date'] - df['session_start']).dt.days.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc816c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['user_id'] == 324558127766]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98c4dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['order_dt'] - df['session_start']).dt.total_seconds().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328e9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diff_seconds = (df['session_end'] - df['session_start']).dt.total_seconds()\n",
    "df_replaced[~(time_diff_seconds >= 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a7e7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diff_seconds = (df['order_dt'] - df['session_start']).dt.total_seconds()\n",
    "(df_replaced[~(time_diff_seconds >= 0) & (time_diff_seconds.notna())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927948b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['order_dt'] < df['session_start']\n",
    "df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5a17d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[mask, 'order_dt'] = df.loc[mask, 'order_dt'].apply(\n",
    "    lambda x: x.replace(year=df.loc[mask, 'session_start'].dt.year.iloc[0], \n",
    "                                    month=df.loc[mask, 'session_start'].dt.month.iloc[0], \n",
    "                                    day=df.loc[mask, 'session_start'].dt.day.iloc[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457675c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c5a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diff_seconds.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b25710",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diff_seconds[time_diff_seconds.notna()].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e5b70e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
