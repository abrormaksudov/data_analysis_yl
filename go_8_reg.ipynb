{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc4c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a8c3c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1009, 19)\n",
      "['user_id', 'region', 'device', 'channel', 'session_start', 'session_end', 'sessiondurationsec', 'session_date', 'month', 'day', 'hour_of_day', 'order_dt', 'revenue', 'payment_type', 'promo_code', 'final_price', 'time_of_day', 'payer', 'week']\n"
     ]
    }
   ],
   "source": [
    "dates = ['session_start', 'session_end', 'session_date', 'order_dt']\n",
    "df = pd.read_csv('ecom_go_2.csv', parse_dates=dates)\n",
    "df['week'] = pd.to_datetime(df['session_date']).dt.isocalendar().week\n",
    "df_pl = pl.from_pandas(df)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d3c3476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1009, 19) 282\n",
      "(1009, 19) 282\n",
      "(1003, 19) 276\n"
     ]
    }
   ],
   "source": [
    "df_unchanged = df.copy()\n",
    "print(df_unchanged.shape, df_unchanged['payer'].sum())\n",
    "\n",
    "df_replaced = df.copy()\n",
    "df_replaced['revenue'] = np.where(df_replaced['revenue'] == 100000, 9999, df_replaced['revenue'])\n",
    "df_replaced['revenue'] = np.where(df_replaced['revenue'] == 1, 4999, df_replaced['revenue'])\n",
    "print(df_replaced.shape, df_replaced['payer'].sum())\n",
    "\n",
    "df_removed = df.copy()\n",
    "to_remove = df[df['revenue'].isin([1, 100000])].index\n",
    "df_removed.drop(to_remove, inplace=True)\n",
    "print(df_removed.shape, df_removed['payer'].sum())\n",
    "\n",
    "\n",
    "dfs = [(df_unchanged, \"ORIGINAL DATAFRAME:\"), \n",
    "       (df_replaced, \"REPLACED DATAFRAME:\"), \n",
    "       (df_removed, \"REMOVED DATAFRAME:\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec490c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85795659",
   "metadata": {},
   "source": [
    "#  Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4d385ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id         region  device          channel       session_start         session_end  sessiondurationsec session_date  month  day  \\\n",
      "0  529697267522  United States  iPhone  социальные сети 2019-05-01 00:06:40 2019-05-01 00:07:06                  26   2019-05-01      5    3   \n",
      "1  601292388085  United States      PC          organic 2019-05-01 06:56:16 2019-05-01 07:09:18                 782   2019-05-01      5    3   \n",
      "2  852898876338  United States     Mac  социальные сети 2019-05-01 04:30:45 2019-05-01 04:34:56                 251   2019-05-01      5    3   \n",
      "3  998513020664  United States  iPhone  социальные сети 2019-05-01 18:53:42 2019-05-01 18:57:35                 233   2019-05-01      5    3   \n",
      "4  240702200943  United States     Mac  социальные сети 2019-05-02 14:04:32 2019-05-02 14:09:51                 319   2019-05-02      5    4   \n",
      "\n",
      "   hour_of_day            order_dt  revenue     payment_type  promo_code  final_price time_of_day  payer  week  \n",
      "0            0 2019-05-01 00:06:40     9999  Mobile payments         0.0       9999.0       night      1    18  \n",
      "1            7                 NaT        0              NaN         NaN          NaN     morning      0    18  \n",
      "2            4                 NaT        0              NaN         NaN          NaN       night      0    18  \n",
      "3           18                 NaT        0              NaN         NaN          NaN     evening      0    18  \n",
      "4           14                 NaT        0              NaN         NaN          NaN         day      0    18  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11d3727c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Logistic Regression Model is ready!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Create a copy of the dataframe\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Select relevant features\n",
    "    features = [\n",
    "        'region', 'device', 'channel', \n",
    "        'sessiondurationsec', 'hour_of_day', \n",
    "        'week', 'time_of_day'\n",
    "    ]\n",
    "    \n",
    "    # Prepare the feature matrix\n",
    "    X = data[features].copy()\n",
    "    y = data['payer']\n",
    "    \n",
    "    # Label Encoding for categorical variables\n",
    "    categorical_cols = ['region', 'device', 'channel', 'time_of_day']\n",
    "    label_encoders = {}\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    # Handle missing values\n",
    "    X = X.fillna(X.median())\n",
    "    \n",
    "    return X, y, label_encoders\n",
    "\n",
    "def train_balanced_logistic_regression(X, y):\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Calculate class weights\n",
    "    class_weights = {0: 1, 1: sum(y_train == 0) / sum(y_train == 1)}\n",
    "    \n",
    "    # Train Balanced Logistic Regression\n",
    "    model = LogisticRegression(\n",
    "        class_weight=class_weights,  # Manual class weights\n",
    "        max_iter=1000, \n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Evaluation\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\nAccuracy Score:\")\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    # Feature Importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': np.abs(model.coef_[0])\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature Importance:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    return model, scaler, feature_importance\n",
    "\n",
    "def main(df):\n",
    "    # Preprocess the data\n",
    "    X, y, label_encoders = preprocess_data(df)\n",
    "    \n",
    "    # Train the model\n",
    "    model, scaler, feature_importance = train_balanced_logistic_regression(X, y)\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'scaler': scaler,\n",
    "        'feature_importance': feature_importance,\n",
    "        'label_encoders': label_encoders\n",
    "    }\n",
    "\n",
    "# Usage: results = main(df)\n",
    "print(\"Balanced Logistic Regression Model is ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2351dd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.55      0.62       146\n",
      "           1       0.26      0.41      0.32        56\n",
      "\n",
      "    accuracy                           0.51       202\n",
      "   macro avg       0.48      0.48      0.47       202\n",
      "weighted avg       0.58      0.51      0.53       202\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[80 66]\n",
      " [33 23]]\n",
      "\n",
      "Accuracy Score:\n",
      "0.5099009900990099\n",
      "\n",
      "Feature Importance:\n",
      "              feature  importance\n",
      "4         hour_of_day    0.204821\n",
      "6         time_of_day    0.108922\n",
      "0              region    0.100870\n",
      "1              device    0.097819\n",
      "5                week    0.095031\n",
      "3  sessiondurationsec    0.061651\n",
      "2             channel    0.044703\n"
     ]
    }
   ],
   "source": [
    "results = main(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83310356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83       143\n",
      "           1       0.00      0.00      0.00        59\n",
      "\n",
      "    accuracy                           0.71       202\n",
      "   macro avg       0.35      0.50      0.41       202\n",
      "weighted avg       0.50      0.71      0.59       202\n",
      "\n",
      "\n",
      "Feature Importances:\n",
      "              feature  importance\n",
      "7         time_of_day    0.174561\n",
      "6         hour_of_day    0.143639\n",
      "2             channel    0.137303\n",
      "3  sessiondurationsec    0.113514\n",
      "1              device    0.110980\n",
      "0              region    0.061888\n",
      "4               month    0.041654\n",
      "5                 day    0.028312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14182/2243076031.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[feature].fillna(data[feature].median(), inplace=True)\n",
      "/tmp/ipykernel_14182/2243076031.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[feature].fillna(data[feature].median(), inplace=True)\n",
      "/tmp/ipykernel_14182/2243076031.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[feature].fillna(data[feature].median(), inplace=True)\n",
      "/tmp/ipykernel_14182/2243076031.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[feature].fillna(data[feature].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data (assuming you'll replace this with your actual data loading)\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the dataframe for logistic regression\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed dataframe\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Feature selection based on potential relevance\n",
    "    selected_features = [\n",
    "        'region', \n",
    "        'device', \n",
    "        'channel', \n",
    "        'sessiondurationsec', \n",
    "        'month', \n",
    "        'day', \n",
    "        'hour_of_day', \n",
    "        'time_of_day'\n",
    "    ]\n",
    "    \n",
    "    # Preprocessing\n",
    "    # 1. Categorical Encoding\n",
    "    categorical_features = ['region', 'device', 'channel', 'time_of_day']\n",
    "    \n",
    "    # Label Encoding for categorical features\n",
    "    le = LabelEncoder()\n",
    "    for feature in categorical_features:\n",
    "        data[feature] = le.fit_transform(data[feature].astype(str))\n",
    "    \n",
    "    # 2. Handle missing values\n",
    "    # Replace NaN with median for numeric features\n",
    "    numeric_features = ['sessiondurationsec', 'month', 'day', 'hour_of_day']\n",
    "    for feature in numeric_features:\n",
    "        data[feature].fillna(data[feature].median(), inplace=True)\n",
    "    \n",
    "    # 3. Prepare features and target\n",
    "    X = data[selected_features]\n",
    "    y = data['payer']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def train_logistic_regression(X, y):\n",
    "    \"\"\"\n",
    "    Train logistic regression model\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): Features\n",
    "        y (pd.Series): Target variable\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Trained model, scaler, classification report, feature importances\n",
    "    \"\"\"\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train logistic regression\n",
    "    lr = LogisticRegression(random_state=42)\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = lr.predict(X_test_scaled)\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Feature importances (absolute values of coefficients)\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': np.abs(lr.coef_[0])\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    return lr, scaler, report, feature_importance\n",
    "\n",
    "def visualize_feature_importance(feature_importance):\n",
    "    \"\"\"\n",
    "    Create a bar plot of feature importances\n",
    "    \n",
    "    Args:\n",
    "        feature_importance (pd.DataFrame): DataFrame with feature importances\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "    plt.title('Feature Importances in Logistic Regression')\n",
    "    plt.xlabel('Absolute Coefficient Value')\n",
    "    plt.ylabel('Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main execution\n",
    "def main(df):\n",
    "    # Preprocess the data\n",
    "    X, y = preprocess_data(df)\n",
    "    \n",
    "    # Train the model\n",
    "    model, scaler, report, feature_importance = train_logistic_regression(X, y)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    print(\"\\nFeature Importances:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    # Visualize feature importances\n",
    "    # visualize_feature_importance(feature_importance)\n",
    "    \n",
    "    return model, scaler\n",
    "\n",
    "# Example usage\n",
    "model, scaler = main(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8af4944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82       139\n",
      "           1       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.69       201\n",
      "   macro avg       0.35      0.50      0.41       201\n",
      "weighted avg       0.48      0.69      0.57       201\n",
      "\n",
      "\n",
      "Feature Importances:\n",
      "              feature  importance\n",
      "1              device    0.150352\n",
      "3  sessiondurationsec    0.147958\n",
      "7         time_of_day    0.099313\n",
      "6         hour_of_day    0.081743\n",
      "0              region    0.076930\n",
      "4               month    0.024461\n",
      "2             channel    0.006443\n",
      "5                 day    0.005996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14182/2243076031.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[feature].fillna(data[feature].median(), inplace=True)\n",
      "/tmp/ipykernel_14182/2243076031.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[feature].fillna(data[feature].median(), inplace=True)\n",
      "/tmp/ipykernel_14182/2243076031.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[feature].fillna(data[feature].median(), inplace=True)\n",
      "/tmp/ipykernel_14182/2243076031.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[feature].fillna(data[feature].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "model, scaler = main(df_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f12a49cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000e+00,          nan,  5.40000e+01,  2.00000e+00,\n",
       "        6.00000e+00,  1.58000e+02,  5.00000e+00,  1.20000e+01,\n",
       "        1.70000e+01,  3.00000e+00,  3.50000e+01,  2.80000e+01,\n",
       "        1.80000e+01,  4.00000e+00,  7.00000e+00,  6.90000e+01,\n",
       "        1.60000e+01, -1.48503e+05,  1.29000e+02,  1.50000e+01,\n",
       "        7.50000e+01,  1.10000e+01,  2.00000e+01,  9.00000e+00,\n",
       "        8.00000e+00,  1.30000e+01,  2.10000e+01,  4.90000e+01,\n",
       "        3.30000e+01,  4.50000e+01,  6.80000e+01,  2.20000e+01,\n",
       "        7.30000e+01,  4.40000e+01,  5.60000e+01,  3.80000e+01,\n",
       "        8.70000e+01,  4.00000e+01,  6.40000e+01,  3.70000e+01,\n",
       "        7.20000e+01,  2.40000e+01,  2.90000e+01,  3.10000e+01,\n",
       "        3.90000e+01,  2.30000e+01,  3.40000e+01,  4.10000e+01,\n",
       "        1.90000e+01,  7.40000e+01])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['order_dt'] - df['session_start']).dt.total_seconds().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44c23abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_start</th>\n",
       "      <th>order_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-01 00:06:40</td>\n",
       "      <td>2019-05-01 00:06:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-05-06 15:49:16</td>\n",
       "      <td>2019-05-06 15:49:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-05-07 12:00:49</td>\n",
       "      <td>2019-05-07 12:01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019-05-09 16:40:44</td>\n",
       "      <td>2019-05-09 16:40:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019-05-09 09:23:22</td>\n",
       "      <td>2019-05-09 09:23:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2019-05-12 07:50:12</td>\n",
       "      <td>2019-05-12 07:50:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2019-05-13 22:00:41</td>\n",
       "      <td>2019-05-13 22:00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2019-05-14 06:32:03</td>\n",
       "      <td>2019-05-14 06:32:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2019-05-15 23:16:53</td>\n",
       "      <td>2019-05-15 23:16:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2019-05-15 15:52:06</td>\n",
       "      <td>2019-05-15 15:52:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2019-05-16 03:22:58</td>\n",
       "      <td>2019-05-16 03:22:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2019-05-17 18:24:36</td>\n",
       "      <td>2019-05-17 18:24:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2019-05-17 17:04:13</td>\n",
       "      <td>2019-05-17 17:04:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2019-05-17 14:14:38</td>\n",
       "      <td>2019-05-17 14:14:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2019-05-17 10:09:01</td>\n",
       "      <td>2019-05-17 10:09:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2019-05-17 13:04:08</td>\n",
       "      <td>2019-05-17 13:04:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2019-05-20 16:55:50</td>\n",
       "      <td>2019-05-20 16:55:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2019-05-21 08:17:29</td>\n",
       "      <td>2019-05-21 08:17:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2019-05-21 14:19:29</td>\n",
       "      <td>2019-05-21 14:19:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2019-05-21 05:50:33</td>\n",
       "      <td>2019-05-21 05:50:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2019-05-22 21:13:06</td>\n",
       "      <td>2019-05-22 21:13:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2019-05-22 14:13:40</td>\n",
       "      <td>2019-05-22 14:13:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2019-05-22 04:11:46</td>\n",
       "      <td>2019-05-22 04:11:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2019-05-23 18:03:52</td>\n",
       "      <td>2019-05-23 18:03:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2019-05-23 13:41:25</td>\n",
       "      <td>2019-05-23 13:41:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2019-05-23 05:31:24</td>\n",
       "      <td>2019-05-23 05:31:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2019-05-24 13:19:44</td>\n",
       "      <td>2019-05-24 13:19:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2019-05-24 07:01:00</td>\n",
       "      <td>2019-05-24 07:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2019-05-27 12:36:38</td>\n",
       "      <td>2019-05-27 12:39:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2019-05-29 13:27:40</td>\n",
       "      <td>2019-05-29 13:27:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_start            order_dt\n",
       "0   2019-05-01 00:06:40 2019-05-01 00:06:40\n",
       "20  2019-05-06 15:49:16 2019-05-06 15:49:16\n",
       "28  2019-05-07 12:00:49 2019-05-07 12:01:43\n",
       "33  2019-05-09 16:40:44 2019-05-09 16:40:44\n",
       "34  2019-05-09 09:23:22 2019-05-09 09:23:24\n",
       "45  2019-05-12 07:50:12 2019-05-12 07:50:12\n",
       "49  2019-05-13 22:00:41 2019-05-13 22:00:41\n",
       "53  2019-05-14 06:32:03 2019-05-14 06:32:03\n",
       "55  2019-05-15 23:16:53 2019-05-15 23:16:53\n",
       "56  2019-05-15 15:52:06 2019-05-15 15:52:06\n",
       "61  2019-05-16 03:22:58 2019-05-16 03:22:58\n",
       "67  2019-05-17 18:24:36 2019-05-17 18:24:36\n",
       "68  2019-05-17 17:04:13 2019-05-17 17:04:13\n",
       "69  2019-05-17 14:14:38 2019-05-17 14:14:38\n",
       "70  2019-05-17 10:09:01 2019-05-17 10:09:01\n",
       "71  2019-05-17 13:04:08 2019-05-17 13:04:08\n",
       "87  2019-05-20 16:55:50 2019-05-20 16:55:56\n",
       "94  2019-05-21 08:17:29 2019-05-21 08:17:29\n",
       "95  2019-05-21 14:19:29 2019-05-21 14:19:29\n",
       "96  2019-05-21 05:50:33 2019-05-21 05:50:33\n",
       "97  2019-05-22 21:13:06 2019-05-22 21:13:06\n",
       "98  2019-05-22 14:13:40 2019-05-22 14:13:40\n",
       "99  2019-05-22 04:11:46 2019-05-22 04:11:46\n",
       "103 2019-05-23 18:03:52 2019-05-23 18:03:52\n",
       "104 2019-05-23 13:41:25 2019-05-23 13:41:25\n",
       "105 2019-05-23 05:31:24 2019-05-23 05:31:24\n",
       "107 2019-05-24 13:19:44 2019-05-24 13:19:44\n",
       "108 2019-05-24 07:01:00 2019-05-24 07:01:00\n",
       "125 2019-05-27 12:36:38 2019-05-27 12:39:16\n",
       "136 2019-05-29 13:27:40 2019-05-29 13:27:40"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['order_dt'].notna()].head(30)[['session_start', 'order_dt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8966b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
